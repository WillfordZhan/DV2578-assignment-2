{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scikit_posthocs as sp\n",
    "import time\n",
    "import copy\n",
    "from tools import *\n",
    "\n",
    "# bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# normal simple dataset division fuction, \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# K-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "\n",
    "# normalization function provided by sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# f1 measure\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# kfold function provided by sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# scipy friedman test\n",
    "from scipy.stats import friedmanchisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv('spambase.data', header=None)\n",
    "\n",
    "# divide X and Y\n",
    "# X is the features matrix of the dataset\n",
    "X = np.array(data)[:, :-1]\n",
    "# Y is the class vector of the dataset\n",
    "Y = np.array(data)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize classifiers\n",
    "\n",
    "# Bayes classifier\n",
    "clf_bayes = GaussianNB()\n",
    "\n",
    "# Decision Tree classifier\n",
    "clf_dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "# Random Forest classifier\n",
    "clf_rf = RandomForestClassifier(criterion=\"gini\", max_features=\"log2\", n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-Fold Stratified by the actual classification\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# list matrix to store the measure results of each algorithm and on each fold.\n",
    "t = []\n",
    "acc = []\n",
    "f1 = []\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X,Y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    fold_acc = []\n",
    "    fold_t = []\n",
    "    fold_f1 = []\n",
    "\n",
    "#     print('Train size: %d | test size: %d' % (len(train), len(test)))\n",
    "#     tr_result = pd.value_counts(Y_train)\n",
    "#     ts_result = pd.value_counts(Y_test)\n",
    "#     print(tr_result)\n",
    "#     print(ts_result)\n",
    "    \n",
    "    # training and computational performance calculation\n",
    "    # bayes\n",
    "    start = time.time()\n",
    "    clf_bayes.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_bayes = end - start\n",
    "    \n",
    "    # decision tree\n",
    "    start = time.time()\n",
    "    clf_dt.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_dt = end - start\n",
    "    \n",
    "    # random forest\n",
    "    start = time.time()\n",
    "    clf_rf.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_rf = end - start\n",
    "    \n",
    "    # measure accuracy\n",
    "    acc_bayes = clf_bayes.score(X_test, Y_test)\n",
    "    acc_dt = clf_dt.score(X_test, Y_test)\n",
    "    acc_rf = clf_rf.score(X_test, Y_test)\n",
    "    \n",
    "    # calculate the f1 of each model\n",
    "    bayes_y_pred = clf_bayes.predict(X_test)\n",
    "    dt_y_pred = clf_dt.predict(X_test)\n",
    "    rf_y_pred = clf_rf.predict(X_test)\n",
    "    f1_bayes = f1_score(Y_test, bayes_y_pred)\n",
    "    f1_dt = f1_score(Y_test, dt_y_pred)\n",
    "    f1_rf = f1_score(Y_test, rf_y_pred)\n",
    "    \n",
    "    # measure results recording\n",
    "    fold_acc.append(acc_bayes)\n",
    "    fold_acc.append(acc_dt)\n",
    "    fold_acc.append(acc_rf)\n",
    "    \n",
    "    fold_f1.append(f1_bayes)\n",
    "    fold_f1.append(f1_dt)\n",
    "    fold_f1.append(f1_rf)\n",
    "    \n",
    "    fold_t.append(t_bayes)\n",
    "    fold_t.append(t_dt)\n",
    "    fold_t.append(t_rf)\n",
    "    \n",
    "    acc.append(fold_acc)\n",
    "    f1.append(fold_f1)\n",
    "    t.append(fold_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Accuracy of 3 Algorithms for each fold ------ Table 12.8\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1           0.81128      0.937093        0.9718\n",
      "D2          0.826464      0.921909      0.956616\n",
      "D3          0.824295      0.921909      0.954447\n",
      "D4          0.826087      0.919565      0.954348\n",
      "D5          0.819565      0.934783      0.978261\n",
      "D6          0.815217      0.926087      0.954348\n",
      "D7          0.813043      0.936957      0.965217\n",
      "D8           0.83913      0.919565      0.952174\n",
      "D9          0.816993      0.901961      0.945534\n",
      "D10         0.810458      0.906318      0.932462\n",
      "--------    --------      --------      --------\n",
      "avg         0.820253      0.922615      0.956521\n",
      "std       0.00888326     0.0119591     0.0129697\n",
      "\n",
      "\n",
      "------ Friedman rank table on Accuracy ------------- Table 12.4\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1                 3             2             1\n",
      "D2                 3             2             1\n",
      "D3                 3             2             1\n",
      "D4                 3             2             1\n",
      "D5                 3             2             1\n",
      "D6                 3             2             1\n",
      "D7                 3             2             1\n",
      "D8                 3             2             1\n",
      "D9                 3             2             1\n",
      "D10                3             2             1\n",
      "--------    --------      --------      --------\n",
      "avg_rank           3             2             1\n",
      "\n",
      "\n",
      "The friedman Test result on Accuracy\n",
      "p =  4.539992976248486e-05  <  0.05\n",
      "Significance difference exists between the Accuracy performance (reject H0)\n",
      "\n",
      "\n",
      "The Nemenyi post-hoc test result on  Accuracy\n",
      "               Naive Bayes  Decision Tree  Random Forest\n",
      "Naive Bayes      -1.000000       0.065303       0.001000\n",
      "Decision Tree     0.065303      -1.000000       0.065303\n",
      "Random Forest     0.001000       0.065303      -1.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the parameters for the procedure\n",
    "column_name = ['Naive Bayes', 'Decision Tree','Random Forest']\n",
    "column_size = 3\n",
    "fold_index = []\n",
    "for i in range(1,11):\n",
    "    idx = 'D'+ str(i)\n",
    "    fold_index.append(idx)\n",
    "\n",
    "# run the whole procedure for a measure\n",
    "def step_2_3_4(data, fold_index, column_name, column_size, is_time, measure):\n",
    "    \n",
    "    # Step 2\n",
    "    # (Table 12.4) generate measure performance table               \n",
    "    df = generate_measure_table(data, fold_index, column_name, column_size)\n",
    "    print('------', measure, 'of 3 Algorithms for each fold ------ Table 12.8')\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    # Step 3\n",
    "    # (Table 12.8) generate measure performance friedman rank table \n",
    "    df = generate_friedman_table(data, fold_index, column_name, column_size,0)\n",
    "    print('------ Friedman rank table on', measure, '------------- Table 12.4')\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    # Step 4\n",
    "    # use the avg rank data of each algorithm to calculate p-value of friedman test \n",
    "    alpha = 0.05\n",
    "    print('The friedman Test result on',measure)\n",
    "    judge_p_of_Friedman(acc,alpha,measure)\n",
    "    print('\\n')\n",
    "    \n",
    "    # use nemenyi post-hoc to test if there's signficant difference between algorithm pairs\n",
    "    generate_nemenyi_table(acc, column_name, 'Accuracy')\n",
    "    print('\\n')\n",
    "    return\n",
    "\n",
    "# show the results\n",
    "# Accuracy\n",
    "step_2_3_4(acc, fold_index, column_name, column_size, 0, 'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------  F1  of 3 Algorithms for each fold ------\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1          0.798165      0.913043      0.944134\n",
      "D2           0.82381      0.903955      0.931818\n",
      "D3          0.782609      0.879121      0.938889\n",
      "D4          0.820513      0.908108      0.963989\n",
      "D5          0.801843      0.895604      0.935211\n",
      "D6          0.811189      0.895604      0.943503\n",
      "D7          0.789954      0.936986      0.954802\n",
      "D8          0.823256      0.914127      0.923944\n",
      "D9          0.810427      0.870027      0.960894\n",
      "D10         0.812207      0.923077      0.942149\n",
      "--------    --------      --------      --------\n",
      "avg         0.807397      0.903965      0.943933\n",
      "std        0.0140411     0.0199092     0.0127337\n",
      "\n",
      "\n",
      "------ Friedman test on  F1  ------\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1                 3             2             1\n",
      "D2                 3             2             1\n",
      "D3                 3             2             1\n",
      "D4                 3             2             1\n",
      "D5                 3             2             1\n",
      "D6                 3             2             1\n",
      "D7                 3             2             1\n",
      "D8                 3             2             1\n",
      "D9                 3             2             1\n",
      "D10                3             2             1\n",
      "--------    --------      --------      --------\n",
      "avg_rank           3             2             1\n",
      "\n",
      "\n",
      "The friedman Test result on F1\n",
      "p =  4.539992976248486e-05  <  0.05\n",
      "Significance difference exists between the F1 performance (reject H0)\n",
      "\n",
      "\n",
      "The Nemenyi post-hoc test result on  Accuracy\n",
      "               Naive Bayes  Decision Tree  Random Forest\n",
      "Naive Bayes      -1.000000       0.065303       0.001000\n",
      "Decision Tree     0.065303      -1.000000       0.065303\n",
      "Random Forest     0.001000       0.065303      -1.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F1 measure\n",
    "step_2_3_4(f1, fold_index, column_name, column_size, 0, 'F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------  Time Consumption  of 3 Algorithms for each fold ------\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1          0.798165      0.913043      0.944134\n",
      "D2           0.82381      0.903955      0.931818\n",
      "D3          0.782609      0.879121      0.938889\n",
      "D4          0.820513      0.908108      0.963989\n",
      "D5          0.801843      0.895604      0.935211\n",
      "D6          0.811189      0.895604      0.943503\n",
      "D7          0.789954      0.936986      0.954802\n",
      "D8          0.823256      0.914127      0.923944\n",
      "D9          0.810427      0.870027      0.960894\n",
      "D10         0.812207      0.923077      0.942149\n",
      "--------    --------      --------      --------\n",
      "avg         0.807397      0.903965      0.943933\n",
      "std        0.0140411     0.0199092     0.0127337\n",
      "\n",
      "\n",
      "------ Friedman test on  Time Consumption  ------\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1                 3             2             1\n",
      "D2                 3             2             1\n",
      "D3                 3             2             1\n",
      "D4                 3             2             1\n",
      "D5                 3             2             1\n",
      "D6                 3             2             1\n",
      "D7                 3             2             1\n",
      "D8                 3             2             1\n",
      "D9                 3             2             1\n",
      "D10                3             2             1\n",
      "--------    --------      --------      --------\n",
      "avg_rank           3             2             1\n",
      "\n",
      "\n",
      "The friedman Test result on Time Consumption\n",
      "p =  4.539992976248486e-05  <  0.05\n",
      "Significance difference exists between the Time Consumption performance (reject H0)\n",
      "\n",
      "\n",
      "The Nemenyi post-hoc test result on  Accuracy\n",
      "               Naive Bayes  Decision Tree  Random Forest\n",
      "Naive Bayes      -1.000000       0.065303       0.001000\n",
      "Decision Tree     0.065303      -1.000000       0.065303\n",
      "Random Forest     0.001000       0.065303      -1.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Time Consumption\n",
    "step_2_3_4(f1, fold_index, column_name, column_size, 0, 'Time Consumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- tool functions ----------------------\n",
    "\n",
    "# generate friedman table\n",
    "def generate_measure_table(data, row_index, column_name, column_size):\n",
    "    size_list = list(range(0,column_size))\n",
    "    df = pd.DataFrame(data)\n",
    "    # get mean and std of the column\n",
    "    mean = df.iloc[:,size_list].mean().values.tolist()\n",
    "    std = df.iloc[:,size_list].std().values.tolist()\n",
    "    \n",
    "    # add index for rows\n",
    "    df = pd.DataFrame(data, index=row_index)\n",
    "    \n",
    "    # add division for mean and std\n",
    "    df.loc['--------'] = ['--------','--------','--------']\n",
    "    df.loc['avg     '] = mean\n",
    "    df.loc['std'] = std\n",
    "    \n",
    "    # add column name\n",
    "    df.columns = column_name\n",
    "    return df\n",
    "\n",
    "# generate friedman table\n",
    "def generate_friedman_table(data, row_index, column_name, column_size, is_time):\n",
    "    size_list = list(range(0,column_size))\n",
    "    \n",
    "    # create rank matrix \n",
    "    # generate friedman test table\n",
    "    data_rank = copy.deepcopy(data)\n",
    "    \n",
    "    # turn the value into rank number\n",
    "    if is_time == 0:\n",
    "        for row in data_rank:\n",
    "            s_row = sorted(enumerate(row), key=lambda x: x[1])\n",
    "            idx = [i[0] for i in s_row]\n",
    "            for index, or_index in enumerate(idx):\n",
    "                row[or_index] = len(idx) - index\n",
    "    else:\n",
    "        for row in data_rank:\n",
    "            s_row = sorted(enumerate(row), key=lambda x: x[1])\n",
    "            idx = [i[0] for i in s_row]\n",
    "            for index, or_index in enumerate(idx):\n",
    "                row[or_index] = index + 1\n",
    "\n",
    "    # get mean rank row\n",
    "    df = pd.DataFrame(data_rank)\n",
    "    mean = df.iloc[:,size_list].mean().values.tolist()\n",
    "\n",
    "    # add index for rows\n",
    "    df = pd.DataFrame(data_rank, index=row_index)\n",
    "    \n",
    "    # add division for mean and std\n",
    "    df.loc['--------'] = ['--------','--------','--------']\n",
    "    df.loc['avg_rank'] = mean\n",
    "    \n",
    "    # add column name\n",
    "    df.columns = column_name\n",
    "    return df\n",
    "\n",
    "# calculate friedman p-value \n",
    "def judge_p_of_Friedman(data, alpha, perf_str):\n",
    "    data_np = np.array(data)\n",
    "    stat, p = friedmanchisquare(data_np[:,0], data_np[:,1], data_np[:,2])\n",
    "    if p > alpha:\n",
    "        print('p = ',p , ' > ', alpha)\n",
    "        print('No significance difference between the',perf_str,'performance (fail to reject H0)')\n",
    "    else:\n",
    "        print('p = ',p , ' < ', alpha)\n",
    "        print('Significance difference exists between the',perf_str,'performance (reject H0)')\n",
    "\n",
    "# run nemenyi test between algorithm pairs\n",
    "def generate_nemenyi_table(data, column_name, measure):\n",
    "    df = sp.posthoc_nemenyi_friedman(data)\n",
    "    df.columns = column_name\n",
    "    df.index = column_name\n",
    "    print('The Nemenyi post-hoc test result on ', measure)\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
