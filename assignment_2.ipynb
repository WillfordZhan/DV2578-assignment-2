{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scikit_posthocs as sp\n",
    "import time\n",
    "\n",
    "# bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# normal simple dataset division fuction, \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# K-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "\n",
    "# normalization function provided by sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# f1 measure\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# kfold function provided by sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# scipy friedman test\n",
    "from scipy.stats import friedmanchisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv('spambase.data', header=None)\n",
    "\n",
    "# divide X and Y\n",
    "# X is the features matrix of the dataset\n",
    "X = np.array(data)[:, :-1]\n",
    "# Y is the label vector of the dataset\n",
    "Y = np.array(data)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize classifiers\n",
    "clf_bayes = GaussianNB()\n",
    "# TODO\n",
    "clf_dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "# TODO\n",
    "clf_rf = RandomForestClassifier(criterion=\"gini\", max_features=\"log2\", n_estimators=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-Fold Stratified by the actual classification\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# accuracy scores array\n",
    "bayes_acc = []\n",
    "dt_acc = []\n",
    "rf_acc = []\n",
    "\n",
    "# matrix provided for friedman and nemenyi post-hoc\n",
    "t = []\n",
    "acc = []\n",
    "f1 = []\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X,Y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    fold_acc = []\n",
    "    fold_t = []\n",
    "    fold_f1 = []\n",
    "    \n",
    "#     # data normalization for training set\n",
    "#     min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#     X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "#     # data normalization for testing set\n",
    "#     # use the transformer(metric) generated by training set to normalize testing set\n",
    "#     X_test_minmax = min_max_scaler.transform(X_test)\n",
    "\n",
    "#     print('Train size: %d | test size: %d' % (len(train), len(test)))\n",
    "#     tr_result = pd.value_counts(Y_train)\n",
    "#     ts_result = pd.value_counts(Y_test)\n",
    "#     print(tr_result)\n",
    "#     print(ts_result)\n",
    "    \n",
    "    # training and computational performance calculation\n",
    "    # bayes\n",
    "    start = time.time()\n",
    "    clf_bayes.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_bayes = end - start\n",
    "    \n",
    "    # decision tree\n",
    "    start = time.time()\n",
    "    clf_dt.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_dt = end - start\n",
    "    \n",
    "    # random forest\n",
    "    start = time.time()\n",
    "    clf_rf.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_rf = end - start\n",
    "    \n",
    "    # calculate the f1 of each model\n",
    "    bayes_y_pred = clf_bayes.predict(X_test)\n",
    "    dt_y_pred = clf_dt.predict(X_test)\n",
    "    rf_y_pred = clf_rf.predict(X_test)\n",
    "    f1_bayes = f1_score(Y_test, bayes_y_pred)\n",
    "    f1_dt = f1_score(Y_test, dt_y_pred)\n",
    "    f1_rf = f1_score(Y_test, rf_y_pred)\n",
    "    \n",
    "    # get accuracy of each model\n",
    "    acc_bayes = clf_bayes.score(X_test, Y_test)\n",
    "    acc_dt = clf_dt.score(X_test, Y_test)\n",
    "    acc_rf = clf_rf.score(X_test, Y_test)\n",
    "    \n",
    "    \n",
    "    bayes_acc.append(acc_bayes)\n",
    "    dt_acc.append(acc_dt)\n",
    "    rf_acc.append(acc_rf)\n",
    "    \n",
    "    fold_acc.append(acc_bayes)\n",
    "    fold_acc.append(acc_dt)\n",
    "    fold_acc.append(acc_rf)\n",
    "    \n",
    "    fold_f1.append(f1_bayes)\n",
    "    fold_f1.append(f1_dt)\n",
    "    fold_f1.append(f1_rf)\n",
    "    \n",
    "    fold_t.append(t_bayes)\n",
    "    fold_t.append(t_dt)\n",
    "    fold_t.append(t_rf)\n",
    "    \n",
    "    acc.append(fold_acc)\n",
    "    f1.append(fold_f1)\n",
    "    t.append(fold_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Accuracy of 3 Algorithms for each fold ------\n",
      "    Naive Bayes Decision Tree Random Forest\n",
      "D1     0.813449      0.921909      0.956616\n",
      "D2     0.826464      0.915401      0.954447\n",
      "D3     0.839479      0.900217      0.941432\n",
      "D4     0.804348      0.902174      0.967391\n",
      "D5     0.823913      0.913043          0.95\n",
      "D6     0.830435      0.934783      0.958696\n",
      "D7          0.8      0.908696      0.947826\n",
      "D8     0.813043      0.921739      0.952174\n",
      "D9     0.830065      0.925926       0.95207\n",
      "D10    0.840959       0.91939       0.96732\n",
      "---    --------      --------      --------\n",
      "avg    0.822216      0.916328      0.954797\n",
      "std   0.0140365     0.0107098    0.00815567\n",
      "\n",
      "\n",
      "--------- F1 of 3 Algorithms for each fold ---------\n",
      "    Naive Bayes Decision Tree Random Forest\n",
      "D1      0.80543           0.9      0.944444\n",
      "D2     0.816514      0.890756      0.940171\n",
      "D3     0.826291      0.874317      0.926027\n",
      "D4     0.791667      0.875346      0.957983\n",
      "D5     0.811189      0.893617       0.93733\n",
      "D6     0.813397      0.916667      0.947368\n",
      "D7     0.787037      0.883333      0.932961\n",
      "D8     0.804545      0.902174      0.939227\n",
      "D9     0.813397      0.903955        0.9375\n",
      "D10    0.826603      0.897507      0.957983\n",
      "---    --------      --------      --------\n",
      "avg    0.809607      0.893767      0.942099\n",
      "std   0.0129978     0.0132802     0.0101956\n",
      "\n",
      "\n",
      "-- Time Consumption of 3 Algorithms for each fold --\n",
      "     Naive Bayes Decision Tree Random Forest\n",
      "D1    0.00402594     0.0424118      0.363177\n",
      "D2    0.00389814     0.0448871      0.341977\n",
      "D3    0.00334692     0.0443668      0.328395\n",
      "D4    0.00510192     0.0433977      0.332536\n",
      "D5    0.00320315     0.0460219      0.317591\n",
      "D6    0.00297499     0.0402954      0.338629\n",
      "D7    0.00329304      0.039377      0.316518\n",
      "D8    0.00326991     0.0411558      0.311511\n",
      "D9    0.00449204     0.0443909      0.329237\n",
      "D10      0.00351     0.0453551      0.326544\n",
      "---     --------      --------      --------\n",
      "avg   0.00371161     0.0431659      0.330611\n",
      "std  0.000668391    0.00226357     0.0149592\n"
     ]
    }
   ],
   "source": [
    "# show the results\n",
    "fold_index = []\n",
    "for i in range(1,11):\n",
    "    idx = 'D'+ str(i)\n",
    "    fold_index.append(idx)\n",
    "\n",
    "# generate result table\n",
    "df_acc = pd.DataFrame(acc)\n",
    "acc_mean = df_acc.iloc[:,[0,1,2]].mean().values.tolist()\n",
    "acc_std = df_acc.iloc[:,[0,1,2]].std().values.tolist()\n",
    "df_acc = pd.DataFrame(acc, index=fold_index)\n",
    "df_acc.loc['---'] = ['--------','--------','--------']\n",
    "df_acc.loc['avg'] = acc_mean\n",
    "df_acc.loc['std'] = acc_std\n",
    "df_acc.columns = ['Naive Bayes', 'Decision Tree','Random Forest']\n",
    "print('------ Accuracy of 3 Algorithms for each fold ------')\n",
    "print(df_acc)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "df_f1 = pd.DataFrame(f1)\n",
    "f1_mean = df_f1.iloc[:,[0,1,2]].mean().values.tolist()\n",
    "f1_std = df_f1.iloc[:,[0,1,2]].std().values.tolist()\n",
    "print('--------- F1 of 3 Algorithms for each fold ---------')\n",
    "df_f1 = pd.DataFrame(f1, index=fold_index)\n",
    "df_f1.loc['---'] = ['--------','--------','--------']\n",
    "df_f1.loc['avg'] = f1_mean\n",
    "df_f1.loc['std'] = f1_std\n",
    "df_f1.columns = ['Naive Bayes', 'Decision Tree','Random Forest']\n",
    "print(df_f1)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "df_t = pd.DataFrame(t)\n",
    "t_mean = df_t.iloc[:,[0,1,2]].mean().values.tolist()\n",
    "t_std = df_t.iloc[:,[0,1,2]].std().values.tolist()\n",
    "print('-- Time Consumption of 3 Algorithms for each fold --')\n",
    "df_t = pd.DataFrame(t, index=fold_index)\n",
    "df_t.loc['---'] = ['--------','--------','--------']\n",
    "df_t.loc['avg'] = t_mean\n",
    "df_t.loc['std'] = t_std\n",
    "df_t.columns = ['Naive Bayes', 'Decision Tree','Random Forest']\n",
    "print(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n",
      "4.539992976248486e-05\n",
      "Significance difference exists between the performance (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# friedman test\n",
    "# input: 3 measurement arrays of the algorithm\n",
    "stat, p = friedmanchisquare(bayes_acc, rf_acc, dt_acc)\n",
    "print(stat)\n",
    "print(p)\n",
    "\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('No significance difference between the performance (fail to reject H0)')\n",
    "else:\n",
    "    print('Significance difference exists between the performance (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0 -1.000000  0.065303  0.001000\n",
      "1  0.065303 -1.000000  0.065303\n",
      "2  0.001000  0.065303 -1.000000\n",
      "          0         1         2\n",
      "0 -1.000000  0.065303  0.001000\n",
      "1  0.065303 -1.000000  0.065303\n",
      "2  0.001000  0.065303 -1.000000\n",
      "          0         1         2\n",
      "0 -1.000000  0.065303  0.001000\n",
      "1  0.065303 -1.000000  0.065303\n",
      "2  0.001000  0.065303 -1.000000\n"
     ]
    }
   ],
   "source": [
    "# print(acc)\n",
    "# print(f1)\n",
    "# print(t)\n",
    "print(sp.posthoc_nemenyi_friedman(acc))\n",
    "print(sp.posthoc_nemenyi_friedman(f1))\n",
    "print(sp.posthoc_nemenyi_friedman(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
