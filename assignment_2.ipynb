{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scikit_posthocs as sp\n",
    "import time\n",
    "import copy\n",
    "from tools import *\n",
    "\n",
    "# bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# normal simple dataset division fuction, \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# K-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "\n",
    "# normalization function provided by sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# f1 measure\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# kfold function provided by sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# scipy friedman test\n",
    "from scipy.stats import friedmanchisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv('spambase.data', header=None)\n",
    "\n",
    "# divide X and Y\n",
    "# X is the features matrix of the dataset\n",
    "X = np.array(data)[:, :-1]\n",
    "# Y is the label vector of the dataset\n",
    "Y = np.array(data)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize classifiers\n",
    "clf_bayes = GaussianNB()\n",
    "# TODO\n",
    "clf_dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "# TODO\n",
    "clf_rf = RandomForestClassifier(criterion=\"gini\", max_features=\"log2\", n_estimators=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-Fold Stratified by the actual classification\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# list matrix to store the measure results of each algorithm and on each fold.\n",
    "t = []\n",
    "acc = []\n",
    "f1 = []\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X,Y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    fold_acc = []\n",
    "    fold_t = []\n",
    "    fold_f1 = []\n",
    "\n",
    "#     print('Train size: %d | test size: %d' % (len(train), len(test)))\n",
    "#     tr_result = pd.value_counts(Y_train)\n",
    "#     ts_result = pd.value_counts(Y_test)\n",
    "#     print(tr_result)\n",
    "#     print(ts_result)\n",
    "    \n",
    "    # training and computational performance calculation\n",
    "    # bayes\n",
    "    start = time.time()\n",
    "    clf_bayes.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_bayes = end - start\n",
    "    \n",
    "    # decision tree\n",
    "    start = time.time()\n",
    "    clf_dt.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_dt = end - start\n",
    "    \n",
    "    # random forest\n",
    "    start = time.time()\n",
    "    clf_rf.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_rf = end - start\n",
    "    \n",
    "    # calculate the f1 of each model\n",
    "    bayes_y_pred = clf_bayes.predict(X_test)\n",
    "    dt_y_pred = clf_dt.predict(X_test)\n",
    "    rf_y_pred = clf_rf.predict(X_test)\n",
    "    f1_bayes = f1_score(Y_test, bayes_y_pred)\n",
    "    f1_dt = f1_score(Y_test, dt_y_pred)\n",
    "    f1_rf = f1_score(Y_test, rf_y_pred)\n",
    "    \n",
    "    # measure results recording\n",
    "    bayes_acc.append(acc_bayes)\n",
    "    dt_acc.append(acc_dt)\n",
    "    rf_acc.append(acc_rf)\n",
    "    \n",
    "    fold_acc.append(acc_bayes)\n",
    "    fold_acc.append(acc_dt)\n",
    "    fold_acc.append(acc_rf)\n",
    "    \n",
    "    fold_f1.append(f1_bayes)\n",
    "    fold_f1.append(f1_dt)\n",
    "    fold_f1.append(f1_rf)\n",
    "    \n",
    "    fold_t.append(t_bayes)\n",
    "    fold_t.append(t_dt)\n",
    "    fold_t.append(t_rf)\n",
    "    \n",
    "    acc.append(fold_acc)\n",
    "    f1.append(fold_f1)\n",
    "    t.append(fold_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Accuracy of 3 Algorithms for each fold ------\n",
      "    Naive Bayes Decision Tree Random Forest\n",
      "D1     0.806941      0.906725      0.937093\n",
      "D2     0.802603      0.937093      0.956616\n",
      "D3     0.813449      0.915401      0.947939\n",
      "D4     0.813043      0.928261       0.96087\n",
      "D5     0.858696      0.919565      0.967391\n",
      "D6     0.836957      0.906522      0.947826\n",
      "D7     0.836957      0.928261      0.971739\n",
      "D8     0.830435      0.917391      0.936957\n",
      "D9     0.810458      0.925926       0.96732\n",
      "D10    0.812636      0.928105      0.965142\n",
      "---    --------      --------      --------\n",
      "avg    0.822217      0.921325      0.955889\n",
      "std   0.0177698    0.00998863     0.0127588\n",
      "\n",
      "\n",
      "--------- F1 of 3 Algorithms for each fold ---------\n",
      "    Naive Bayes Decision Tree Random Forest\n",
      "D1     0.796339      0.881543       0.91922\n",
      "D2     0.793651      0.920548      0.943503\n",
      "D3     0.799065      0.893733      0.934066\n",
      "D4     0.803653      0.909589          0.95\n",
      "D5     0.844869      0.899183      0.958904\n",
      "D6     0.821002      0.880886      0.932203\n",
      "D7     0.823529      0.910082      0.963173\n",
      "D8     0.816038      0.893855      0.918768\n",
      "D9          0.8      0.906077      0.958449\n",
      "D10    0.799065      0.909091      0.955556\n",
      "---    --------      --------      --------\n",
      "avg    0.809721      0.900459      0.943384\n",
      "std   0.0162923     0.0129829     0.0165094\n",
      "\n",
      "\n",
      "-- Time Consumption of 3 Algorithms for each fold --\n",
      "    Naive Bayes Decision Tree Random Forest\n",
      "D1   0.00450182     0.0431869       0.28793\n",
      "D2   0.00324893      0.039371      0.292452\n",
      "D3   0.00316119     0.0391588       0.33285\n",
      "D4   0.00514007      0.041925      0.288386\n",
      "D5     0.003196      0.041652      0.291782\n",
      "D6   0.00300598     0.0401711      0.283626\n",
      "D7   0.00315595     0.0393763      0.282348\n",
      "D8   0.00393224     0.0487552      0.311556\n",
      "D9   0.00300789     0.0407438      0.337614\n",
      "D10  0.00307608     0.0418868       0.33776\n",
      "---    --------      --------      --------\n",
      "avg  0.00354261     0.0416227       0.30463\n",
      "std  0.00073912    0.00283916     0.0231508\n"
     ]
    }
   ],
   "source": [
    "# set parameter for self-made table generator\n",
    "column_name = ['Naive Bayes', 'Decision Tree','Random Forest']\n",
    "column_size = 3\n",
    "fold_index = []\n",
    "for i in range(1,11):\n",
    "    idx = 'D'+ str(i)\n",
    "    fold_index.append(idx)\n",
    "\n",
    "# show the results\n",
    "df_acc = generate_measure_table(acc, fold_index, column_name, column_size)\n",
    "print('------ Accuracy of 3 Algorithms for each fold ------')\n",
    "print(df_acc)\n",
    "print('\\n')\n",
    "\n",
    "df_f1 = generate_measure_table(f1, fold_index, column_name, column_size)\n",
    "print('--------- F1 of 3 Algorithms for each fold ---------')\n",
    "print(df_f1)\n",
    "print('\\n')\n",
    "\n",
    "df_t = generate_measure_table(t, fold_index, column_name, column_size)\n",
    "print('-- Time Consumption of 3 Algorithms for each fold --')\n",
    "print(df_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Friedman test on Accuracy ------\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1                 3             2             1\n",
      "D2                 3             2             1\n",
      "D3                 3             2             1\n",
      "D4                 3             2             1\n",
      "D5                 3             2             1\n",
      "D6                 3             2             1\n",
      "D7                 3             2             1\n",
      "D8                 3             2             1\n",
      "D9                 3             2             1\n",
      "D10                3             2             1\n",
      "--------    --------      --------      --------\n",
      "avg_rank           3             2             1\n",
      "\n",
      "\n",
      "--------- Friedman test on F1 ---------\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1                 3             2             1\n",
      "D2                 3             2             1\n",
      "D3                 3             2             1\n",
      "D4                 3             2             1\n",
      "D5                 3             2             1\n",
      "D6                 3             2             1\n",
      "D7                 3             2             1\n",
      "D8                 3             2             1\n",
      "D9                 3             2             1\n",
      "D10                3             2             1\n",
      "--------    --------      --------      --------\n",
      "avg_rank           3             2             1\n",
      "\n",
      "\n",
      "-- Friedman test on Time Consumption --\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1                 1             2             3\n",
      "D2                 1             2             3\n",
      "D3                 1             2             3\n",
      "D4                 1             2             3\n",
      "D5                 1             2             3\n",
      "D6                 1             2             3\n",
      "D7                 1             2             3\n",
      "D8                 1             2             3\n",
      "D9                 1             2             3\n",
      "D10                1             2             3\n",
      "--------    --------      --------      --------\n",
      "avg_rank           1             2             3\n"
     ]
    }
   ],
   "source": [
    "# rank the performance of\n",
    "df_acc = generate_friedman_table(acc, fold_index, column_name, column_size,0)\n",
    "print('------ Friedman test on Accuracy ------')\n",
    "print(df_acc)\n",
    "print('\\n')\n",
    "\n",
    "df_f1 = generate_friedman_table(f1, fold_index, column_name, column_size,0)\n",
    "print('--------- Friedman test on F1 ---------')\n",
    "print(df_f1)\n",
    "print('\\n')\n",
    "\n",
    "df_t = generate_friedman_table(t, fold_index, column_name, column_size,1)\n",
    "print('-- Friedman test on Time Consumption --')\n",
    "print(df_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The friedman Test result on Accuracy\n",
      "p =  4.539992976248486e-05  <  0.05\n",
      "Significance difference exists between the Accuracy performance (reject H0)\n",
      "\n",
      "The friedman Test result on F1\n",
      "p =  4.539992976248486e-05  <  0.05\n",
      "Significance difference exists between the F1 performance (reject H0)\n",
      "\n",
      "The friedman Test result on Computational performance\n",
      "p =  4.539992976248486e-05  <  0.05\n",
      "Significance difference exists between the Computational performance (reject H0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# friedman test\n",
    "# input: 3 measurement arrays of the algorithm\n",
    "# TODO: use numpy to get column of the data instead of arrays\n",
    "acc_np = np.array(acc)\n",
    "f1_np = np.array(f1)\n",
    "t_np = np.array(t)\n",
    "stat, p_acc = friedmanchisquare(acc_np[:,0], acc_np[:,1], acc_np[:,2])\n",
    "stat, p_f1 = friedmanchisquare(f1_np[:,0], f1_np[:,1], f1_np[:,2])\n",
    "stat, p_t = friedmanchisquare(t_np[:,0], t_np[:,1], t_np[:,2])\n",
    "\n",
    "def judge_p(p, alpha, perf_str):\n",
    "    if p > alpha:\n",
    "        print('p = ',p , ' > ', alpha)\n",
    "        print('No significance difference between the',perf_str,'performance (fail to reject H0)')\n",
    "    else:\n",
    "        print('p = ',p , ' < ', alpha)\n",
    "        print('Significance difference exists between the',perf_str,'performance (reject H0)')\n",
    "\n",
    "alpha = 0.05\n",
    "print('The friedman Test result on Accuracy')\n",
    "judge_p(p_acc,alpha,'Accuracy')\n",
    "print()\n",
    "\n",
    "print('The friedman Test result on F1')\n",
    "judge_p(p_f1,alpha,'F1')\n",
    "print()\n",
    "\n",
    "print('The friedman Test result on Computational performance')\n",
    "judge_p(p_t,alpha,'Computational')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0 -1.000000  0.065303  0.001000\n",
      "1  0.065303 -1.000000  0.065303\n",
      "2  0.001000  0.065303 -1.000000\n",
      "          0         1         2\n",
      "0 -1.000000  0.065303  0.001000\n",
      "1  0.065303 -1.000000  0.065303\n",
      "2  0.001000  0.065303 -1.000000\n",
      "          0         1         2\n",
      "0 -1.000000  0.065303  0.001000\n",
      "1  0.065303 -1.000000  0.065303\n",
      "2  0.001000  0.065303 -1.000000\n"
     ]
    }
   ],
   "source": [
    "# print(acc)\n",
    "# print(f1)\n",
    "# print(t)\n",
    "print(sp.posthoc_nemenyi_friedman(acc))\n",
    "print(sp.posthoc_nemenyi_friedman(f1))\n",
    "print(sp.posthoc_nemenyi_friedman(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
