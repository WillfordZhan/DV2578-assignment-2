{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "from tools import *\n",
    "\n",
    "# bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# normal simple dataset division fuction, \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# K-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "\n",
    "# f1 measure\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# scipy friedman test\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# nemenyi test function inside\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- tool functions , just run and skip it ----------------------\n",
    "\n",
    "# generate friedman table\n",
    "def generate_measure_table(data, row_index, column_name, column_size):\n",
    "    size_list = list(range(0,column_size))\n",
    "    df = pd.DataFrame(data)\n",
    "    # get mean and std of the column\n",
    "    mean = df.iloc[:,size_list].mean().values.tolist()\n",
    "    std = df.iloc[:,size_list].std().values.tolist()\n",
    "    \n",
    "    # add index for rows\n",
    "    df = pd.DataFrame(data, index=row_index)\n",
    "    \n",
    "    # add division for mean and std\n",
    "    df.loc['--------'] = ['--------','--------','--------']\n",
    "    df.loc['avg     '] = mean\n",
    "    df.loc['std'] = std\n",
    "    \n",
    "    # add column name\n",
    "    df.columns = column_name\n",
    "    return df\n",
    "\n",
    "# generate friedman table\n",
    "def generate_friedman_table(data, row_index, column_name, column_size, is_time):\n",
    "    size_list = list(range(0,column_size))\n",
    "    \n",
    "    # create rank matrix \n",
    "    # generate friedman test table\n",
    "    data_rank = copy.deepcopy(data)\n",
    "    \n",
    "    # turn the value into rank number\n",
    "    if is_time == 0:\n",
    "        for row in data_rank:\n",
    "            s_row = sorted(enumerate(row), key=lambda x: x[1])\n",
    "            idx = [i[0] for i in s_row]\n",
    "            for index, or_index in enumerate(idx):\n",
    "                row[or_index] = len(idx) - index\n",
    "    else:\n",
    "        for row in data_rank:\n",
    "            s_row = sorted(enumerate(row), key=lambda x: x[1])\n",
    "            idx = [i[0] for i in s_row]\n",
    "            for index, or_index in enumerate(idx):\n",
    "                row[or_index] = index + 1\n",
    "\n",
    "    # get mean rank row\n",
    "    df = pd.DataFrame(data_rank)\n",
    "    mean = df.iloc[:,size_list].mean().values.tolist()\n",
    "\n",
    "    # add index for rows\n",
    "    df = pd.DataFrame(data_rank, index=row_index)\n",
    "    \n",
    "    # add division for mean and std\n",
    "    df.loc['--------'] = ['--------','--------','--------']\n",
    "    df.loc['avg_rank'] = mean\n",
    "    \n",
    "    # add column name\n",
    "    df.columns = column_name\n",
    "    return df\n",
    "\n",
    "# calculate friedman p-value \n",
    "def judge_stat_of_Friedman(data, stat, perf_str):\n",
    "    data_np = np.array(data)\n",
    "    q, p = friedmanchisquare(data_np[:,0], data_np[:,1], data_np[:,2])\n",
    "    if q < stat:\n",
    "        print('Q = ',q , ' < ', stat)\n",
    "        print('No significant difference between the',perf_str,'performance (fail to reject H0)')\n",
    "    else:\n",
    "        print('Q = ',q , ' > ', stat)\n",
    "        print('Significant difference exists between the',perf_str,'performance (reject H0)')\n",
    "\n",
    "# run nemenyi test between algorithm pairs\n",
    "def generate_nemenyi_table(data, column_name, measure):\n",
    "    df = sp.posthoc_nemenyi_friedman(data)\n",
    "    df.columns = column_name\n",
    "    df.index = column_name\n",
    "    print('The Nemenyi post-hoc test result on ', measure)\n",
    "    print(df)\n",
    "    \n",
    "# run the whole procedure for a measure\n",
    "def step_2_3_4(data, fold_index, column_name, column_size, is_time, measure):\n",
    "    \n",
    "    # Step 2\n",
    "    # (Table 12.4) generate measure performance table               \n",
    "    df = generate_measure_table(data, fold_index, column_name, column_size)\n",
    "    print('------', measure, 'of 3 Algorithms for each fold ------ Table 12.4')\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    # Step 3\n",
    "    # (Table 12.8) generate measure performance friedman rank table \n",
    "    df = generate_friedman_table(data, fold_index, column_name, column_size,is_time)\n",
    "    print('------ Friedman rank table on', measure, '------------- Table 12.8')\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    # Step 4\n",
    "    # use the avg rank data of each algorithm to calculate p-value of friedman test \n",
    "    stat = 7.82\n",
    "    print('The friedman Test result on',measure)\n",
    "    judge_stat_of_Friedman(acc,stat,measure)\n",
    "    print('\\n')\n",
    "    \n",
    "    # use nemenyi post-hoc to test if there's signficant difference between algorithm pairs\n",
    "    generate_nemenyi_table(acc, column_name, measure)\n",
    "    print('\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv('spambase.data', header=None)\n",
    "\n",
    "# divide X and Y\n",
    "# X is the features matrix of the dataset\n",
    "X = np.array(data)[:, :-1]\n",
    "# Y is the class vector of the dataset\n",
    "Y = np.array(data)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize classifiers\n",
    "\n",
    "# Bayes classifier\n",
    "clf_bayes = GaussianNB()\n",
    "\n",
    "# Decision Tree classifier\n",
    "clf_dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "# Random Forest classifier\n",
    "clf_rf = RandomForestClassifier(criterion=\"gini\", max_features=\"log2\", n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-Fold Stratified by the actual classification\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# list matrix to store the measure results of each algorithm and on each fold.\n",
    "t = []\n",
    "acc = []\n",
    "f1 = []\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X,Y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    fold_acc = []\n",
    "    fold_t = []\n",
    "    fold_f1 = []\n",
    "    \n",
    "    # training and time calculation\n",
    "    # bayes\n",
    "    start = time.time()\n",
    "    clf_bayes.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_bayes = end - start\n",
    "    \n",
    "    # decision tree\n",
    "    start = time.time()\n",
    "    clf_dt.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_dt = end - start\n",
    "    \n",
    "    # random forest\n",
    "    start = time.time()\n",
    "    clf_rf.fit(X_train, Y_train)\n",
    "    end = time.time()\n",
    "    t_rf = end - start\n",
    "    \n",
    "    # measure accuracy\n",
    "    acc_bayes = clf_bayes.score(X_test, Y_test)\n",
    "    acc_dt = clf_dt.score(X_test, Y_test)\n",
    "    acc_rf = clf_rf.score(X_test, Y_test)\n",
    "    \n",
    "    # measure f1 of each model\n",
    "    bayes_y_pred = clf_bayes.predict(X_test)\n",
    "    dt_y_pred = clf_dt.predict(X_test)\n",
    "    rf_y_pred = clf_rf.predict(X_test)\n",
    "    f1_bayes = f1_score(Y_test, bayes_y_pred)\n",
    "    f1_dt = f1_score(Y_test, dt_y_pred)\n",
    "    f1_rf = f1_score(Y_test, rf_y_pred)\n",
    "    \n",
    "    # measure results recording\n",
    "    fold_acc.append(acc_bayes)\n",
    "    fold_acc.append(acc_dt)\n",
    "    fold_acc.append(acc_rf)\n",
    "    \n",
    "    fold_f1.append(f1_bayes)\n",
    "    fold_f1.append(f1_dt)\n",
    "    fold_f1.append(f1_rf)\n",
    "    \n",
    "    fold_t.append(t_bayes)\n",
    "    fold_t.append(t_dt)\n",
    "    fold_t.append(t_rf)\n",
    "    \n",
    "    acc.append(fold_acc)\n",
    "    f1.append(fold_f1)\n",
    "    t.append(fold_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Accuracy of 3 Algorithms for each fold ------ Table 12.4\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1          0.854664      0.926247      0.958785\n",
      "D2          0.832972       0.94577      0.963124\n",
      "D3          0.796095      0.908894      0.952278\n",
      "D4          0.826087      0.934783      0.963043\n",
      "D5              0.85      0.902174          0.95\n",
      "D6          0.819565      0.930435      0.963043\n",
      "D7           0.81087      0.934783      0.967391\n",
      "D8          0.815217      0.921739      0.952174\n",
      "D9          0.784314      0.915033      0.941176\n",
      "D10         0.821351      0.908497      0.941176\n",
      "--------    --------      --------      --------\n",
      "avg         0.821113      0.922835      0.955219\n",
      "std        0.0217248      0.014023    0.00934142\n",
      "\n",
      "\n",
      "------ Friedman rank table on Accuracy ------------- Table 12.8\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1                 3             2             1\n",
      "D2                 3             2             1\n",
      "D3                 3             2             1\n",
      "D4                 3             2             1\n",
      "D5                 3             2             1\n",
      "D6                 3             2             1\n",
      "D7                 3             2             1\n",
      "D8                 3             2             1\n",
      "D9                 3             2             1\n",
      "D10                3             2             1\n",
      "--------    --------      --------      --------\n",
      "avg_rank           3             2             1\n",
      "\n",
      "\n",
      "The friedman Test result on Accuracy\n",
      "Q =  20.0  >  7.82\n",
      "Significant difference exists between the Accuracy performance (reject H0)\n",
      "\n",
      "\n",
      "The Nemenyi post-hoc test result on  Accuracy\n",
      "               Naive Bayes  Decision Tree  Random Forest\n",
      "Naive Bayes      -1.000000       0.065303       0.001000\n",
      "Decision Tree     0.065303      -1.000000       0.065303\n",
      "Random Forest     0.001000       0.065303      -1.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the parameters for the procedure\n",
    "column_name = ['Naive Bayes', 'Decision Tree','Random Forest']\n",
    "column_size = 3\n",
    "fold_index = []\n",
    "for i in range(1,11):\n",
    "    idx = 'D'+ str(i)\n",
    "    fold_index.append(idx)\n",
    "\n",
    "# show the results\n",
    "# Accuracy Comparision\n",
    "step_2_3_4(acc, fold_index, column_name, column_size, 0, 'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ F1 of 3 Algorithms for each fold ------ Table 12.4\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1          0.834568      0.910053      0.947368\n",
      "D2          0.818824      0.929972      0.952113\n",
      "D3          0.788288      0.884615      0.938889\n",
      "D4          0.816514      0.919355      0.953168\n",
      "D5          0.834532       0.87395      0.935574\n",
      "D6          0.808314      0.910112      0.952381\n",
      "D7          0.802721      0.916201      0.957507\n",
      "D8          0.803695      0.900552      0.939227\n",
      "D9          0.771363      0.894879      0.923944\n",
      "D10         0.809302      0.884615       0.92437\n",
      "--------    --------      --------      --------\n",
      "avg         0.808812       0.90243      0.942454\n",
      "std         0.019356     0.0178207      0.012007\n",
      "\n",
      "\n",
      "------ Friedman rank table on F1 ------------- Table 12.8\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1                 3             2             1\n",
      "D2                 3             2             1\n",
      "D3                 3             2             1\n",
      "D4                 3             2             1\n",
      "D5                 3             2             1\n",
      "D6                 3             2             1\n",
      "D7                 3             2             1\n",
      "D8                 3             2             1\n",
      "D9                 3             2             1\n",
      "D10                3             2             1\n",
      "--------    --------      --------      --------\n",
      "avg_rank           3             2             1\n",
      "\n",
      "\n",
      "The friedman Test result on F1\n",
      "Q =  20.0  >  7.82\n",
      "Significant difference exists between the F1 performance (reject H0)\n",
      "\n",
      "\n",
      "The Nemenyi post-hoc test result on  F1\n",
      "               Naive Bayes  Decision Tree  Random Forest\n",
      "Naive Bayes      -1.000000       0.065303       0.001000\n",
      "Decision Tree     0.065303      -1.000000       0.065303\n",
      "Random Forest     0.001000       0.065303      -1.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F1 measure Comparision\n",
    "step_2_3_4(f1, fold_index, column_name, column_size, 0, 'F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Time Consumption of 3 Algorithms for each fold ------ Table 12.4\n",
      "          Naive Bayes Decision Tree Random Forest\n",
      "D1         0.00511718     0.0457041      0.416781\n",
      "D2         0.00302792     0.0386612      0.407837\n",
      "D3         0.00308299     0.0472541       0.42256\n",
      "D4         0.00382614     0.0394831      0.400536\n",
      "D5         0.00339603      0.040956      0.405085\n",
      "D6         0.00338936      0.040432      0.401904\n",
      "D7          0.0034461       0.04088      0.408856\n",
      "D8         0.00366378     0.0405681      0.398348\n",
      "D9         0.00327206     0.0386629      0.404066\n",
      "D10        0.00318098     0.0398679      0.397418\n",
      "--------     --------      --------      --------\n",
      "avg        0.00354025     0.0412469      0.406339\n",
      "std       0.000606328    0.00289967    0.00805716\n",
      "\n",
      "\n",
      "------ Friedman rank table on Time Consumption ------------- Table 12.8\n",
      "         Naive Bayes Decision Tree Random Forest\n",
      "D1                 1             2             3\n",
      "D2                 1             2             3\n",
      "D3                 1             2             3\n",
      "D4                 1             2             3\n",
      "D5                 1             2             3\n",
      "D6                 1             2             3\n",
      "D7                 1             2             3\n",
      "D8                 1             2             3\n",
      "D9                 1             2             3\n",
      "D10                1             2             3\n",
      "--------    --------      --------      --------\n",
      "avg_rank           1             2             3\n",
      "\n",
      "\n",
      "The friedman Test result on Time Consumption\n",
      "Q =  20.0  >  7.82\n",
      "Significant difference exists between the Time Consumption performance (reject H0)\n",
      "\n",
      "\n",
      "The Nemenyi post-hoc test result on  Time Consumption\n",
      "               Naive Bayes  Decision Tree  Random Forest\n",
      "Naive Bayes      -1.000000       0.065303       0.001000\n",
      "Decision Tree     0.065303      -1.000000       0.065303\n",
      "Random Forest     0.001000       0.065303      -1.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Time Consumption Comparision\n",
    "step_2_3_4(t, fold_index, column_name, column_size, 1, 'Time Consumption')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
